---
layout: page
title: Latent & Implicit Thinking – Going Beyond CoT Reasoning
---

We are pleased to announce the **Latent & Implicit Thinking – Going Beyond CoT Reasoning (LIT)** workshop at ICLR 2026. AI models have demonstrated remarkable reasoning capabilities by explicitly generating intermediate steps in natural language, an approach known as Chain-of-Thought (CoT) reasoning. While CoT reasoning has become the dominant paradigm for reasoning in AI systems, it incurs substantial computational costs due to the increasing length and complexity of the generated reasoning chains. Moreover, although autoregressive natural language reasoning aligns intuitively with human cognition, it may not represent the most efficient or effective internal computation medium for neural networks. Thus, emerging bodies of research are exploring alternative forms of intermediate reasoning, including using continuous hidden representations, learning discrete reasoning tokens optimized for efficiency rather than readability, and other non-autoregressive thinking approaches. These alternative paradigms present promising opportunities to achieve more efficient and potentially more powerful implicit reasoning capabilities within future AI models. The **Latent & Implicit Thinking – Going Beyond CoT Reasoning (LIT)** workshop seeks to unify these diverse yet complementary research directions. By fostering interdisciplinary dialogue among researchers pursuing implicit reasoning strategies, novel model architectures, and non-autoregressive generative frameworks, we aim to deepen our collective understanding of how to harness and extend LLMs' inherent implicit reasoning capacities.

## Submit Your Paper

**[Submit via OpenReview →](https://openreview.net/group?id=ICLR.cc/2026/Workshop/LIT)** | **[Call for Papers →](https://latent-implicit-thinking.github.io/callforpapers/)**

**Submission deadline**: January 30, 2026

## Topics of Interest

We invite original submissions on, but not limited to, the following themes:

- **Training Strategy for Implicit Reasoning**: e.g., curriculum learning, distillation, reinforcement learning, and pretraining from scratch.
- **Looped Architectures**: Recurrence mechanisms (loop unrolling, dynamic halting). Training curricula and stability for deep iterative models.
- **Mechanical Interpretability of Implicit Reasoning**: Layer-wise specialization and attribution of reasoning functions. Causal interventions on intermediate representations.
- **Special Thinking Tokens**: Text CoT compressed to special tokens (e.g., continuous thought tokens, VQ-VAE codes, gist tokens). CoT augmentation via filler or planning tokens.
- **KV-Cache and Hybrid Stateful Reasoning**: Leveraging key/value caches for multi-step latent inference. Comparisons between pure activation vs. cache-augmented loops.
- **Inference Paradigms Beyond Autoregression**: Text diffusion for bidirectional, iterative denoising-based reasoning. Fractal generative frameworks and next-block prediction.
- **Theoretical Results on Depth, Scaling, and Efficiency**: Theoretical bounds on reasoning depth vs. layer count. Parameter- and compute-efficient designs for implicit reasoning.
- **Evaluation and Benchmarks**: Metrics and probes for implicit vs. explicit CoT capabilities. Datasets and tasks that stress ultra-deep or multi-hop latent reasoning.
- **Limitations and Safety**: Understanding pros and cons of implicit and explicit CoT, and interpretability & faithfulness of reasoning from a safety and alignment perspective.

## Important Dates

- **Submission deadline**: January 30, 2026
- **Reviewing period**: January 30 - February 28, 2026
- **Notification of acceptance**: March 1, 2026, 11:59pm AoE
- **Camera-ready deadline**: March 10, 2026
- **Workshop date**: April 26-27, 2026 (Rio de Janeiro, following the ICLR 2026 main conference)

