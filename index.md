---
layout: page
title: "Latent & Implicit Thinking – Going Beyond CoT Reasoning"
---

We are pleased to announce the **Latent & Implicit Thinking – Going Beyond CoT Reasoning (LIT)** workshop at ICLR 2026. While autoregressive chain-of-thought (CoT) reasoning aligns intuitively with human cognition, it may not represent the most efficient or effective internal computation medium for neural networks. Emerging research is exploring alternative forms of intermediate reasoning, including continuous hidden representations, discrete reasoning tokens optimized for efficiency rather than readability, and other non-autoregressive thinking approaches such as diffusion-based thinking. These approaches open up exciting possibilities for more efficient and potentially more capable implicit reasoning in future AI systems. The LIT workshop aims to bring together researchers across the spectrum of implicit reasoning to spark collaboration and accelerate progress in this emerging area.

## Submit Your Paper

**[Submit via OpenReview →](https://openreview.net/group?id=ICLR.cc/2026/Workshop/LIT)** | **[Call for Papers →](https://latent-implicit-thinking.github.io/callforpapers/)**

**Submission deadline**: January 30, 2026

## Topics of Interest

We invite original submissions on, but not limited to, the following themes:

- **Training Strategy for Implicit Reasoning**: e.g., curriculum learning, distillation, reinforcement learning, and pretraining from scratch.
- **Looped Architectures**: Recurrence mechanisms (loop unrolling, dynamic halting). Training curricula and stability for deep iterative models.
- **Mechanical Interpretability of Implicit Reasoning**: Layer-wise specialization and attribution of reasoning functions. Causal interventions on intermediate representations.
- **Special Thinking Tokens**: Text CoT compressed to special tokens (e.g., continuous thought tokens, VQ-VAE codes, gist tokens). CoT augmentation via filler or planning tokens.
- **KV-Cache and Hybrid Stateful Reasoning**: Leveraging key/value caches for multi-step latent inference. Comparisons between pure activation vs. cache-augmented loops.
- **Inference Paradigms Beyond Autoregression**: Text diffusion for bidirectional, iterative denoising-based reasoning. Fractal generative frameworks and next-block prediction.
- **Theoretical Results on Depth, Scaling, and Efficiency**: Theoretical bounds on reasoning depth vs. layer count. Parameter- and compute-efficient designs for implicit reasoning.
- **Evaluation and Benchmarks**: Metrics and probes for implicit vs. explicit CoT capabilities. Datasets and tasks that stress ultra-deep or multi-hop latent reasoning.
- **Limitations and Safety**: Understanding pros and cons of implicit and explicit CoT, and interpretability & faithfulness of reasoning from a safety and alignment perspective.

## Important Dates

- **Submission deadline**: January 30, 2026
- **Reviewing period**: January 30 - February 28, 2026
- **Notification of acceptance**: March 1, 2026, 11:59pm AoE
- **Camera-ready deadline**: March 10, 2026
- **Workshop date**: April 26-27, 2026 (Rio de Janeiro, following the ICLR 2026 main conference)

